from __future__ import absolute_import, division, print_function, \
    unicode_literals
import csv
import numpy as np

from sklearn.model_selection import train_test_split
from learning_model import get_compiled_model
from data_processing import DataProcessor


def classify_data(alarm_data, classification_label_data, filepath,
                  input_dimension, input_num, dropout, output):
    '''
    Trains on the data passed as input. This function initializes the structure
    of the learning model, specific to the classification label.

    Parameters:

    alarm_data: encoded alarm values

    classification_label_data: label data in the form of numpy array

    filepath: name of the .hdf5 saved model state file

    input_dimension: input dimenesion for learning model

    input_num: number of neurons for input layer

    dropout: dropout rate for learning model

    output: number of output neurons per classification label

    x_data is what is fed into the NN. This will be the encoded alarm
    values for each ticket.

    y_data are the encoded label values that correspond to each ticket.
    '''
    x_data = alarm_data[:2132]
    y_data = classification_label_data[:2132]

    x_train, x_test, y_train, y_test = train_test_split(x_data,
                                                        y_data,
                                                        test_size=0.20,
                                                        random_state=0)

    model = get_compiled_model(input_dimension, input_num, dropout, output)

    # Epochs pass the data n times through the system
    history = model.fit(x_train,
                        y_train,
                        epochs=20,
                        batch_size=20,
                        validation_data=(x_test, y_test),
                        verbose=0)

    # saves the model in the filepath listed
    model.save('./models/' + filepath)

    # Eval accuracy of model on test data using the test labels in the file
    test_results = model.evaluate(x_test, y_test)
    train_results = model.evaluate(x_train, y_train)

    print(history.model)
    print("Test Evaluation: " + str(test_results))
    print("Train Evaluation: " + str(train_results))


def convert_test_data(filename, alarm_file, ticket_file):
    '''
    Function converts the encoded hex values to numpy arrays. Returns converted
    data in form of numpy array.

    Parameters:

    filename: prediction filename

    alarm_file: alarm file required for DataProcessor object

    ticket_file: ticket file required for DataProcessor object
    '''
    dp = DataProcessor(alarm_file, ticket_file)
    test_alarm_values = []
    with open(filename, encoding='utf8') as csv_file:
        reader = csv.reader(csv_file)
        next(reader)
        for row in reader:
            test_alarm_values.append(row[3])

    result_list = []
    for item in test_alarm_values:
        encoded_alarm = dp.encode_hex_values(item)
        result_list.append(encoded_alarm)

    return dp.convert_array_to_np_array(result_list)


def report_prediction_results(predicted_arr, label_arr):
    '''
    This function will take in a data set and provide the labels for the
    maximum confidence label index value. This will report the results as an
    array of values similar to the content of the ticket data file. Returns
    array of subarrays containing label as a string.

    Parameters:

    predicted_arr: predicted arrays of output generated by the learning model

    label_arr: class member of DataProcessor used to retrieve the string
                  representation of the prediction
    '''
    result_arr = []

    length_of_array = len(predicted_arr)
    num_of_vals = len(predicted_arr[0])

    # loops through rows
    for rows in range(length_of_array):
        greatest_percent = max(predicted_arr[rows])
        position = 0

        # gets the index of largest confidence value
        for index in range(num_of_vals):
            if predicted_arr[rows][index] == greatest_percent:
                position = index

        result_arr.append(label_arr[position])

    return result_arr


def report_ticket_id(filename):
    '''
    Function will iterate through the provided alarm filename and collect the
    incident ID values in that file. Returns array of incident ID's.

    Argument:

    filename: name of CSV file containing alarm related incident ID's.
    '''

    result_arr = []

    with open(filename, encoding='utf8') as csv_file:
        csv_reader = csv.reader(csv_file)
        # Skip first row in the file
        next(csv_reader)
        for row in csv_reader:
            result_arr.append(row[0])

    return result_arr


def validation(prediction_list, result_array, input_hex, filename):
    '''
    Function will create an output of the encoded hex code array (Hex Code),
    the correct classification (Actual) as an encoded array (length of output
    layer for learning model), predicition (Result), and boolean value
    determining if prediction was correct (Correctly Classified). Returns float
    of true value over the total number of values being predicted.

    Parameters:

    prediction_list: list of values in the original ticket file

    result_array: list of predicted values generated by learning model

    input_hex: hex value inputs that correlate to ticket file incident ID's

    filename: resulting filename that will store results of this function
    '''

    with open(filename, mode='w') as csv_file:
        fieldnames = ['Hex Code', 'Actual',
                      'Result', 'Correctly Classified']
        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)

        writer.writeheader()

        # Converting np arrays to lists
        # predict_actual = np.array(predict_actual).tolist()
        predict_actual = np.array(prediction_list).tolist()
        result_array = np.array(result_array).tolist()

        length_of_array = len(input_hex)
        num_of_vals = len(predict_actual[0])
        true_counter = 0

        # loops through rows
        for rows in range(length_of_array):
            greatest_percent = max(result_array[rows])
            boolean = False
            position = 0

            # gets the index of largest confidence value
            for index in range(num_of_vals):
                if result_array[rows][index] == greatest_percent:
                    position = index

            # if the index of largest confidence value equals the index of
            # actual classification
            for index in range(num_of_vals):
                if predict_actual[rows][index] == 1 and index == position:
                    boolean = True
                    true_counter += 1

            writer.writerow({'Hex Code': input_hex[rows],
                             'Actual': predict_actual[rows],
                             'Result': result_array[rows],
                             'Correctly Classified': boolean})
        csv_file.close()

    return true_counter / length_of_array
